{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_spotlight.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_job_file(fname, header, job_list):\n",
    "    with open(fname, 'w+', newline='\\n') as f:\n",
    "        f.write(header)\n",
    "        f.write('case $PBS_ARRAY_INDEX in\\n')\n",
    "        for job_num, job_str in enumerate(jobs):\n",
    "            f.write(f'{job_num+1})\\n{job_str}\\n;;\\n')\n",
    "        f.write('esac\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run many spotlights each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_iterative_jobs(datasets, spotlight_sizes, num_spotlights):   \n",
    "    \"\"\"\n",
    "    datasets: list of (\n",
    "        dataset_name, \n",
    "        examples in dataset, \n",
    "        spherical (True/False), \n",
    "        dimensions to use (or None for all),\n",
    "        flip_objective (True/False),\n",
    "        barrier scale (or None for default)\n",
    "    )\n",
    "    \"\"\"\n",
    "    device = 'cuda' \n",
    "    inference_path = '/scratch/st-kevinlb-1/will/jupyter/spotlight/inference_results'\n",
    "    spotlight_path = '/scratch/st-kevinlb-1/will/jupyter/spotlight/spotlight_results'\n",
    "    \n",
    "    jobs = []\n",
    "    for (dataset_name, dataset_size, spherical, num_dimensions, flip_objective, barrier_scale) in datasets:\n",
    "        for spotlight_fraction in spotlight_sizes:\n",
    "            spotlight_num_points = int(spotlight_fraction * dataset_size)\n",
    "            job = ''\n",
    "            previous_outputs = []\n",
    "            for spotlight_num in range(num_spotlights):\n",
    "                extra_args = ''\n",
    "                if spherical:\n",
    "                    extra_args += '--spherical \\\\\\n'\n",
    "                if num_dimensions is not None:\n",
    "                    extra_args += '--top_components %d \\\\\\n' % (num_dimensions) \n",
    "                if flip_objective:\n",
    "                    extra_args += '--flip_objective \\\\\\n'\n",
    "                if spotlight_num > 0:\n",
    "                    extra_args += '--past_weights ' + ' '.join(previous_outputs) + ' \\\\\\n'\n",
    "                if barrier_scale is not None:\n",
    "                    extra_args += '--barrier_scale %f \\\\\\n' % (barrier_scale)\n",
    "                output_path = ''.join([\n",
    "                    spotlight_path + '/' + dataset_name,\n",
    "                    '_' + str(spotlight_fraction),\n",
    "                    ('_%dD' % num_dimensions if num_dimensions is not None else ''),\n",
    "                    ('_spherical' if spherical else ''),\n",
    "                    ('_flip' if flip_objective else ''),\n",
    "                    '_' + str(spotlight_num+1) + '.pkl'\n",
    "                ])\n",
    "                job += f\"\"\"python /scratch/st-kevinlb-1/will/jupyter/spotlight/torch_spotlight/run_spotlight.py \\\\\n",
    "{spotlight_num_points} \\\\\n",
    "{inference_path}/{dataset_name}.pkl \\\\\n",
    "{output_path} \\\\\n",
    "--learning_rate 1e-2 \\\\\n",
    "--lr_patience 10 \\\\\n",
    "--print_every 20 \\\\\n",
    "--device {device} \\\\\n",
    "--num_steps 5000 \\\\\n",
    "{extra_args}\n",
    "\"\"\"\n",
    "                previous_outputs.append(output_path)\n",
    "            jobs.append(job)\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs: 8\n"
     ]
    }
   ],
   "source": [
    "jobs = generate_iterative_jobs(\n",
    "    datasets = [\n",
    "        ('waterbirds_train_resnet', 4795, True, None, False, 1),\n",
    "    ],\n",
    "    spotlight_sizes = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2], \n",
    "    num_spotlights = 5\n",
    ")\n",
    "\n",
    "header = f\"\"\"#!/bin/bash\n",
    "#PBS -l walltime=6:00:00,select=1:ncpus=1:ngpus=1:mem=32gb\n",
    "#PBS -N spotlight-waterbirds\n",
    "#PBS -A st-kevinlb-1-gpu\n",
    "#PBS -o /scratch/st-kevinlb-1/will/jupyter/spotlight/job_outputs/output-iwild-^array_index^.txt\n",
    "#PBS -e /scratch/st-kevinlb-1/will/jupyter/spotlight/job_outputs/error-iwild-^array_index^.txt\n",
    "#PBS -J 1-{len(jobs)}\n",
    "\n",
    "module load python3\n",
    "\"\"\"\n",
    "\n",
    "print('jobs: %d' % len(jobs))\n",
    "write_job_file('scripts/run_spotlights_waterbirds_train.pbs', header, jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs: 8\n"
     ]
    }
   ],
   "source": [
    "jobs = generate_iterative_jobs(\n",
    "    datasets = [\n",
    "        ('waterbirds_val_resnet', 1199, True, None, False, 1),\n",
    "    ],\n",
    "    spotlight_sizes = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2], \n",
    "    num_spotlights = 5\n",
    ")\n",
    "\n",
    "header = f\"\"\"#!/bin/bash\n",
    "#PBS -l walltime=6:00:00,select=1:ncpus=1:ngpus=1:mem=32gb\n",
    "#PBS -N spotlight-waterbirds\n",
    "#PBS -A st-kevinlb-1-gpu\n",
    "#PBS -o /scratch/st-kevinlb-1/will/jupyter/spotlight/job_outputs/output-iwild-^array_index^.txt\n",
    "#PBS -e /scratch/st-kevinlb-1/will/jupyter/spotlight/job_outputs/error-iwild-^array_index^.txt\n",
    "#PBS -J 1-{len(jobs)}\n",
    "\n",
    "module load python3\n",
    "\"\"\"\n",
    "\n",
    "print('jobs: %d' % len(jobs))\n",
    "write_job_file('scripts/run_spotlights_waterbirds_val.pbs', header, jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs: 8\n"
     ]
    }
   ],
   "source": [
    "jobs = generate_iterative_jobs(\n",
    "    datasets = [\n",
    "        ('waterbirds_test_resnet', 5794, True, None, False, 1),\n",
    "    ],\n",
    "    spotlight_sizes = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2], \n",
    "    num_spotlights = 5\n",
    ")\n",
    "\n",
    "header = f\"\"\"#!/bin/bash\n",
    "#PBS -l walltime=6:00:00,select=1:ncpus=1:ngpus=1:mem=32gb\n",
    "#PBS -N spotlight-waterbirds\n",
    "#PBS -A st-kevinlb-1-gpu\n",
    "#PBS -o /scratch/st-kevinlb-1/will/jupyter/spotlight/job_outputs/output-iwild-^array_index^.txt\n",
    "#PBS -e /scratch/st-kevinlb-1/will/jupyter/spotlight/job_outputs/error-iwild-^array_index^.txt\n",
    "#PBS -J 1-{len(jobs)}\n",
    "\n",
    "module load python3\n",
    "\"\"\"\n",
    "\n",
    "print('jobs: %d' % len(jobs))\n",
    "write_job_file('scripts/run_spotlights_waterbirds_test.pbs', header, jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
